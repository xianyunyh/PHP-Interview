## 架构和设计

架构和设计是面试中经常用到的，一是考察你的知识面，而是考察你接触的系统的复杂程序。本文可能介绍一些相关的问题。### 1. 数据库结构设计

- 主从复制
- 分库分表
- 双主互备
- 数据库中间件



为了解决单表数据过多，一般会采取分片【分库分表】水平切分，分片会产生路由，上层应用要知道数据在哪一个库中。路由规则常用的有三种方法

- range 范围

- 哈希
- 路由服务

#### 可用性

为了解决单点的故障，一般引入 ** 主从复制 **，也就是垂直分割。采取 ** 双主互备 **【keplived】，冗余写库，双主当主从用 

解决同步冲突，有两种常见解决方案 

- 两个写库设置不同的初始化，相同步长增加 id
- 业务层自己生成唯一的 id，保证数据不冲突 

#### 一致性

主从数据库的一致性，通常有两种解决方案：- 中间件

中间件屏蔽了集群了，对外伪装成一个 server。- 强制读主

### SESSION 架构设计

服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文。只要用户不重启浏览器，会话就一直存在。- session 同步法：多台 web-server 相互同步数据 
- 客户端存储法：一个用户只存储自己的数据
-  反向代理 hash 一致性：四层 hash 和七层 hash 都可以做，保证一个用户的请求落在一台 web-server 上 
- 后端统一存储：web-server 重启和扩容，session 也不会丢失 

## 缓存架构设计

淘汰缓存机制（1）淘汰缓存是一种通用的缓存处理方式（2）先 ** 淘汰缓存，再写数据库 ** 的时序是毋庸置疑的（3）服务化是向业务方屏蔽底层数据库与缓存复杂性的一种通用方式



设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应 

### 缓存穿透

缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。### 缓存穿透解决方案

有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被 这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。### 缓存雪崩

缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。### 缓存雪崩解决方案

缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如 1 - 5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。### 缓存击穿

对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多 key。缓存在某个时间点过期的时候，恰好在这个时间点对这个 Key 有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。### 缓存击穿 解决方案

#### 1. 使用互斥锁（mutex key)

业界比较常用的做法，是使用 mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去 load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的 SETNX 或者 Memcache 的 ADD）去 set 一个 mutex key，当操作返回成功时，再进行 load db 的操作并回设缓存；否则，就重试整个 get 缓存的方法。SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在 redis2.6.1 之前版本未实现 setnx 的过期时间

#### 2. "提前" 使用互斥锁（mutex key)：在 value 内部设置 1 个超时值 (timeout1), timeout1 比实际的 memcache timeout(timeout2) 小。当从 cache 读取到 timeout1 发现它已经过期时候，马上延长 timeout1 并重新设置到 cache。然后再从数据库加载数据并设置到 cache 中

#### 3. "永远不过期"：这里的“永远不过期”包含两层意思：> (1) 从 redis 上看，确实没有设置过期时间，这就保证了，不会出现热点 key 过期问题，也就是“物理”不过期。>
> (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在 Key 对应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

​        从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程 (非构建缓存的线程） 可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。#### 4. 资源保护：采用 netflix 的 hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。四种解决方案：没有最佳只有最合适

| 解决方案                      | 优点                                                     | 缺点                                                         |
| ----------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| 简单分布式互斥锁（mutex Key）| 1. 思路简单  2. 保证一致性                               | 1. 代码复杂度增大  2. 存在死锁的风险  3. 存在线程池阻塞的风险 |
|“提前”使用互斥锁              | 1. 保证一致性                                            | 同上                                                         |
| 不过期（本文）                  | 1. 异步构建缓存，不会阻塞线程池                          | 1. 不保证一致性。2. 代码复杂度增大（每个 value 都要维护一个 timekey)。3. 占用一定的内存空间（每个 value 都要维护一个 timekey)。|
| 资源隔离组件 hystrix(本文）     | 1. hystrix 技术成熟，有效保证后端。2. hystrix 监控强大。| 1. 部分访问存在降级策略。|

 